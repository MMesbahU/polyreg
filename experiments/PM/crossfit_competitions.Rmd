---
title: "Crossfit Data"
output: github_document
---

```{r, echo=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment="")
log_odds <- function(x, divide_by=100, scale=0.99){
  p <- scale*x/divide_by
  log(p/(1-p))
}

```

```{r}
library(kerasformula)
library(polyreg)
```

Below find publically-available data from the Crossfit annual open, an amateur athletics competition consisting of five workouts each year. "Rx", as in "perscription", denotes the heaviest weights and most complex movements. In this analysis, we restrict the predictors to height, weight, age, region, and performance in the first of the five rounds. We also restrict analysis who did all five rounds "Rx" and reported that other data. The analysis is repeated for men and women and 2017 and 2018. In each case, `kerasformula` and `xvalPoly` are compared in terms of mean absolute error. (Note `kms` will standardize the outcome by default and so the test stats are on the same scale).

# Men 2018 Competition

```{r}

MAE_results <- matrix(nrow=2, ncol=4, dimnames=list(c("kms", "xvalPoly"), c("m2018", "m2017", "w2018", "w2017")))

Rx <- read.csv("Men_Rx_2018.csv")
```
```{r}
colnames(Rx) <- gsub("[[:punct:]]", "", colnames(Rx))    # forgetmenot
colnames(Rx) <- tolower(colnames(Rx))
colnames(Rx) <- gsub("x18", "open", colnames(Rx))

Rx_tmp <- dplyr::select(Rx, heightm, weightkg, age, open1percentile, overallpercentile)
Rx_complete <- Rx_tmp[complete.cases(Rx_tmp), ]
dim(Rx_complete)
head(Rx_complete)

P <- ncol(model.matrix(overallpercentile ~ ., Rx_complete))

Rx_kms_out <- kms(overallpercentile ~ ., Rx_complete, 
                  layers = list(units = c(P, P, NA), 
                                activation = c("relu", "relu", "linear"), 
                                dropout = c(0.4, 0.3, NA), 
                                use_bias = TRUE, 
                                kernel_initializer = NULL, 
                                kernel_regularizer = "regularizer_l1_l2", 
                                bias_regularizer = "regularizer_l1_l2", 
                                activity_regularizer = "regularizer_l1_l2"),
                  seed=77777, Nepochs=5, 
                  validation_split = 0, pTraining = 0.9)
```

```{r}
Rx_complete_z <- as.data.frame(lapply(Rx_complete, kerasformula:::z))
xval.out <- xvalPoly(Rx_complete_z, maxDeg = 3, maxInteractDeg = 2)
xval.out
Rx_kms_out$MAE_predictions
MAE_results[1,1] <- Rx_kms_out$MAE_predictions
MAE_results[2,1] <- min(xval.out)
```

# Men 2017 Competition

```{r}
Rx <- read.csv("Men_Rx_2017.csv")
```

```{r}
colnames(Rx) <- gsub("[[:punct:]]", "", colnames(Rx))    # forgetmenot
colnames(Rx) <- tolower(colnames(Rx))
colnames(Rx) <- gsub("x17", "open", colnames(Rx))

Rx_tmp <- dplyr::select(Rx, heightm, weightkg, age, open1percentile, overallpercentile)
Rx_complete <- Rx_tmp[complete.cases(Rx_tmp), ]
dim(Rx_complete)

Rx_kms_out <- kms(overallpercentile ~ ., Rx_complete, 
                  layers = list(units = c(P, P, NA), 
                                activation = c("relu", "relu", "linear"), 
                                dropout = c(0.4, 0.3, NA), 
                                use_bias = TRUE, 
                                kernel_initializer = NULL, 
                                kernel_regularizer = "regularizer_l1_l2", 
                                bias_regularizer = "regularizer_l1_l2", 
                                activity_regularizer = "regularizer_l1_l2"),
                  seed=77777, Nepochs=5, 
                  validation_split = 0, pTraining = 0.9)
```

```{r}
Rx_complete_z <- as.data.frame(lapply(Rx_complete, kerasformula:::z))
xval.out <- xvalPoly(Rx_complete_z, maxDeg = 3, maxInteractDeg = 1)
xval.out
Rx_kms_out$MAE_predictions
MAE_results[1,2] <- Rx_kms_out$MAE_predictions
MAE_results[2,2] <- min(xval.out)
```

# Women 2018 Competition

```{r}
Rx <- read.csv("Women_Rx_2018.csv")
```

```{r}
colnames(Rx) <- gsub("[[:punct:]]", "", colnames(Rx))    # forgetmenot
colnames(Rx) <- tolower(colnames(Rx))
colnames(Rx) <- gsub("x18", "open", colnames(Rx))

Rx_tmp <- dplyr::select(Rx, heightm, weightkg, age, open1percentile, overallpercentile)
Rx_complete <- Rx_tmp[complete.cases(Rx_tmp), ]
dim(Rx_complete)

Rx_kms_out <- kms(overallpercentile ~ ., Rx_complete, 
                  layers = list(units = c(P, P, NA), 
                                activation = c("relu", "relu", "linear"), 
                                dropout = c(0.4, 0.3, NA), 
                                use_bias = TRUE, 
                                kernel_initializer = NULL, 
                                kernel_regularizer = "regularizer_l1_l2", 
                                bias_regularizer = "regularizer_l1_l2", 
                                activity_regularizer = "regularizer_l1_l2"),
                  seed=77777, Nepochs=5, 
                  validation_split = 0, pTraining = 0.9)

Rx_complete_z <- as.data.frame(lapply(Rx_complete, kerasformula:::z))
```
```{r}
xval.out <- xvalPoly(Rx_complete_z, maxDeg = 3, maxInteractDeg = 1)
xval.out
Rx_kms_out$MAE_predictions
MAE_results[1,3] <- Rx_kms_out$MAE_predictions
MAE_results[2,3] <- min(xval.out)
```

# Women 2017
```{r}
Rx <- read.csv("Women_Rx_2017.csv")
```


```{r}
colnames(Rx) <- gsub("[[:punct:]]", "", colnames(Rx))    # forgetmenot
colnames(Rx) <- tolower(colnames(Rx))
colnames(Rx) <- gsub("x17", "open", colnames(Rx))

Rx_tmp <- dplyr::select(Rx, heightm, weightkg, age, open1percentile, overallpercentile)
Rx_complete <- Rx_tmp[complete.cases(Rx_tmp), ]
dim(Rx_complete)

Rx_kms_out <- kms(overallpercentile ~ ., Rx_complete, 
                  layers = list(units = c(P, P, NA), 
                                activation = c("relu", "relu", "linear"), 
                                dropout = c(0.4, 0.3, NA), 
                                use_bias = TRUE, 
                                kernel_initializer = NULL, 
                                kernel_regularizer = "regularizer_l1_l2", 
                                bias_regularizer = "regularizer_l1_l2", 
                                activity_regularizer = "regularizer_l1_l2"),
                  seed=77777, Nepochs=5, 
                  validation_split = 0, pTraining = 0.9)
```

```{r}
Rx_complete_z <- as.data.frame(lapply(Rx_complete, kerasformula:::z))
xval.out <- xvalPoly(Rx_complete_z, maxDeg = 3, maxInteractDeg = 1)
xval.out
Rx_kms_out$MAE_predictions
MAE_results[1,4] <- Rx_kms_out$MAE_predictions
MAE_results[2,4] <- min(xval.out)
```

# The results

Out-of-sample mean absolute error (MAE) for `kms` vs. `xvalPoly` (for the latter, the lowest MAE for the models corresponding to the three polynomial degrees is selected).
```{r}
MAE_results

```
